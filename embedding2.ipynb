{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1PnVXOs9A5HcDkB67upwB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redpineK/deeplearning/blob/master/embedding2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출처 - https://www.kaggle.com/code/rajmehra03/a-detailed-explanation-of-keras-embedding-layer/notebook"
      ],
      "metadata": {
        "id": "GDgsoBhMoXRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore  the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# data visualisation and manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "#configure\n",
        "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
        "%matplotlib inline  \n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid',color_codes=True)"
      ],
      "metadata": {
        "id": "-oFJt8ixmw4e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haZqbsspnF7r",
        "outputId": "31f97935-fb53-436d-99ea-c06ae4f8b6fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RG4FPvkAi8y7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#nltk\n",
        "# import nltk\n",
        "\n",
        "#stop-words\n",
        "# from nltk.corpus import stopwords\n",
        "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# tokenizing\n",
        "from nltk import word_tokenize,sent_tokenize\n",
        "#keras\n",
        "import keras\n",
        "from keras.preprocessing.text import one_hot,Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Flatten ,Embedding,Input\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text_1=\"bitty bought a bit of butter\"\n",
        "sample_text_2=\"but the bit of butter was a bit bitter\"\n",
        "sample_text_3=\"so she bought some better butter to make the bitter butter better\"\n",
        "\n",
        "corp=[sample_text_1,sample_text_2,sample_text_3]\n",
        "no_docs=len(corp)"
      ],
      "metadata": {
        "id": "Nf44iddAk_J5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=50 \n",
        "encod_corp=[]\n",
        "for i,doc in enumerate(corp):\n",
        "    encod_corp.append(one_hot(doc,50))\n",
        "    print(\"The encoding for document\",i+1,\" is : \",one_hot(doc,50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMdBwb4ilCND",
        "outputId": "5e3fa9fa-63b1-445a-eb10-1636777b0419"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The encoding for document 1  is :  [47, 35, 26, 47, 44, 19]\n",
            "The encoding for document 2  is :  [36, 14, 47, 44, 19, 47, 26, 47, 3]\n",
            "The encoding for document 3  is :  [5, 34, 35, 48, 2, 19, 46, 48, 14, 3, 19, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# length of maximum document. will be nedded whenever create embeddings for the words\n",
        "maxlen=-1\n",
        "for doc in corp:\n",
        "    tokens=nltk.word_tokenize(doc)\n",
        "    if(maxlen<len(tokens)):\n",
        "        maxlen=len(tokens)\n",
        "print(\"The maximum number of words in any document is : \",maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8y4C-nblMDg",
        "outputId": "b46600dd-2eed-470f-8c4d-78bcedc8d809"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum number of words in any document is :  12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now to create embeddings all of our docs need to be of same length. hence we can pad the docs with zeros.\n",
        "pad_corp=pad_sequences(encod_corp,maxlen=maxlen,padding='post',value=0.0)\n",
        "print(\"No of padded documents: \",len(pad_corp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGy-ktzDlRO5",
        "outputId": "333d88cd-5af9-4dca-f1f1-5b8811c23723"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of padded documents:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,doc in enumerate(pad_corp):\n",
        "     print(\"The padded encoding for document\",i+1,\" is : \",doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad6b-Dn2lUBk",
        "outputId": "bf837243-997c-4de0-cc3b-df3320c63333"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The padded encoding for document 1  is :  [47 35 26 47 44 19  0  0  0  0  0  0]\n",
            "The padded encoding for document 2  is :  [36 14 47 44 19 47 26 47  3  0  0  0]\n",
            "The padded encoding for document 3  is :  [ 5 34 35 48  2 19 46 48 14  3 19  2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specifying the input shape\n",
        "input=Input(shape=(no_docs,maxlen),dtype='float64')"
      ],
      "metadata": {
        "id": "cvrjn-JslX4N"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "shape of input. \n",
        "each document has 12 element or words which is the value of our maxlen variable.\n",
        "\n",
        "'''\n",
        "word_input=Input(shape=(maxlen,),dtype='float64')  \n",
        "\n",
        "# creating the embedding\n",
        "word_embedding=Embedding(input_dim=vocab_size,output_dim=8,input_length=maxlen)(word_input)\n",
        "\n",
        "word_vec=Flatten()(word_embedding) # flatten\n",
        "embed_model =Model([word_input],word_vec) # combining all into a Keras model"
      ],
      "metadata": {
        "id": "FpGCx7n2lbQv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model.compile(optimizer=keras.optimizers.Adam(lr=1e-3),loss='binary_crossentropy',metrics=['acc']) \n",
        "# compiling the model. parameters can be tuned as always."
      ],
      "metadata": {
        "id": "WuY4gYR3ljZa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(word_embedding))\n",
        "print(word_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTsd66H0l2XK",
        "outputId": "3bc3712f-23bf-4c5e-dbd5-566f0d048955"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'keras.engine.keras_tensor.KerasTensor'>\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 12, 8), dtype=tf.float32, name=None), name='embedding/embedding_lookup/Identity_1:0', description=\"created by layer 'embedding'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed_model.summary()) # summary of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT0YxdbUl40f",
        "outputId": "12708e4d-7654-4779-fe4a-c512cb9df38f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 12)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 12, 8)             400       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 96)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 400\n",
            "Trainable params: 400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=embed_model.predict(pad_corp) # finally getting the embeddings."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTESSdY3l7Wh",
        "outputId": "0c1f1dc5-37cc-45fe-cb2d-7122b8a8da30"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 187ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of embeddings : \",embeddings.shape)\n",
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yayuNoGal9YF",
        "outputId": "de9e272e-e17a-483f-fb84-d62a76a4654b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embeddings :  (3, 96)\n",
            "[[ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467 -0.01063299\n",
            "  -0.04568898 -0.02832687  0.00406151 -0.04067155 -0.0216952  -0.03526106\n",
            "   0.0099689  -0.01227249 -0.01924158 -0.03416069 -0.00846242 -0.02669038\n",
            "  -0.03737707 -0.03100523  0.01753208 -0.00716165 -0.03958933  0.02342893\n",
            "   0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467 -0.01063299\n",
            "  -0.04568898 -0.02832687 -0.03213499  0.00381348 -0.0323016  -0.02118363\n",
            "   0.03843411 -0.01977954 -0.0376313   0.00078212 -0.04762596 -0.03199545\n",
            "  -0.00610454  0.00913912  0.04712454  0.0447777   0.03903276  0.04508351\n",
            "   0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "   0.04576981  0.02851266  0.00998991 -0.0211266   0.01373998  0.00513347\n",
            "   0.02413077  0.0463694   0.04576981  0.02851266  0.00998991 -0.0211266\n",
            "   0.01373998  0.00513347  0.02413077  0.0463694   0.04576981  0.02851266\n",
            "   0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "   0.04576981  0.02851266  0.00998991 -0.0211266   0.01373998  0.00513347\n",
            "   0.02413077  0.0463694   0.04576981  0.02851266  0.00998991 -0.0211266\n",
            "   0.01373998  0.00513347  0.02413077  0.0463694   0.04576981  0.02851266]\n",
            " [ 0.02495926 -0.02276956 -0.0166773  -0.0218321   0.01099371 -0.04513886\n",
            "  -0.01044786  0.03824759  0.0327018   0.04490184 -0.04767594  0.01570619\n",
            "  -0.01002353  0.03499526 -0.04567767 -0.00960311  0.00021515  0.04049387\n",
            "  -0.04500476 -0.00864762 -0.02606467 -0.01063299 -0.04568898 -0.02832687\n",
            "  -0.03213499  0.00381348 -0.0323016  -0.02118363  0.03843411 -0.01977954\n",
            "  -0.0376313   0.00078212 -0.04762596 -0.03199545 -0.00610454  0.00913912\n",
            "   0.04712454  0.0447777   0.03903276  0.04508351  0.00021515  0.04049387\n",
            "  -0.04500476 -0.00864762 -0.02606467 -0.01063299 -0.04568898 -0.02832687\n",
            "  -0.00846242 -0.02669038 -0.03737707 -0.03100523  0.01753208 -0.00716165\n",
            "  -0.03958933  0.02342893  0.00021515  0.04049387 -0.04500476 -0.00864762\n",
            "  -0.02606467 -0.01063299 -0.04568898 -0.02832687  0.04840124 -0.03601875\n",
            "   0.00335134  0.01281032  0.03751023 -0.01557592  0.02940439  0.04567841\n",
            "   0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "   0.04576981  0.02851266  0.00998991 -0.0211266   0.01373998  0.00513347\n",
            "   0.02413077  0.0463694   0.04576981  0.02851266  0.00998991 -0.0211266\n",
            "   0.01373998  0.00513347  0.02413077  0.0463694   0.04576981  0.02851266]\n",
            " [ 0.03787452 -0.02205776  0.02461043 -0.04462063  0.03276087 -0.03106458\n",
            "  -0.00696957 -0.00905617 -0.03256357 -0.04965434  0.03093023 -0.00784104\n",
            "   0.0271985  -0.00038449 -0.03985684 -0.02427249  0.00406151 -0.04067155\n",
            "  -0.0216952  -0.03526106  0.0099689  -0.01227249 -0.01924158 -0.03416069\n",
            "   0.00117755  0.03518093 -0.01943209  0.03198161 -0.02390835 -0.01308385\n",
            "  -0.03958635  0.04204347  0.03289417 -0.02797817 -0.00894807  0.00598838\n",
            "   0.00729679 -0.01798836 -0.02862849  0.00577153 -0.04762596 -0.03199545\n",
            "  -0.00610454  0.00913912  0.04712454  0.0447777   0.03903276  0.04508351\n",
            "   0.02656425 -0.03522559 -0.03719143 -0.00033368 -0.03100518  0.01129659\n",
            "   0.02967956 -0.0300315   0.00117755  0.03518093 -0.01943209  0.03198161\n",
            "  -0.02390835 -0.01308385 -0.03958635  0.04204347  0.0327018   0.04490184\n",
            "  -0.04767594  0.01570619 -0.01002353  0.03499526 -0.04567767 -0.00960311\n",
            "   0.04840124 -0.03601875  0.00335134  0.01281032  0.03751023 -0.01557592\n",
            "   0.02940439  0.04567841 -0.04762596 -0.03199545 -0.00610454  0.00913912\n",
            "   0.04712454  0.0447777   0.03903276  0.04508351  0.03289417 -0.02797817\n",
            "  -0.00894807  0.00598838  0.00729679 -0.01798836 -0.02862849  0.00577153]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=embeddings.reshape(-1,maxlen,8)\n",
        "print(\"Shape of embeddings : \",embeddings.shape) \n",
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5EHgOMFmBAk",
        "outputId": "5050f01c-04b4-471b-a22c-9c70e1d40856"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embeddings :  (3, 12, 8)\n",
            "[[[ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467\n",
            "   -0.01063299 -0.04568898 -0.02832687]\n",
            "  [ 0.00406151 -0.04067155 -0.0216952  -0.03526106  0.0099689\n",
            "   -0.01227249 -0.01924158 -0.03416069]\n",
            "  [-0.00846242 -0.02669038 -0.03737707 -0.03100523  0.01753208\n",
            "   -0.00716165 -0.03958933  0.02342893]\n",
            "  [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467\n",
            "   -0.01063299 -0.04568898 -0.02832687]\n",
            "  [-0.03213499  0.00381348 -0.0323016  -0.02118363  0.03843411\n",
            "   -0.01977954 -0.0376313   0.00078212]\n",
            "  [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454\n",
            "    0.0447777   0.03903276  0.04508351]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]]\n",
            "\n",
            " [[ 0.02495926 -0.02276956 -0.0166773  -0.0218321   0.01099371\n",
            "   -0.04513886 -0.01044786  0.03824759]\n",
            "  [ 0.0327018   0.04490184 -0.04767594  0.01570619 -0.01002353\n",
            "    0.03499526 -0.04567767 -0.00960311]\n",
            "  [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467\n",
            "   -0.01063299 -0.04568898 -0.02832687]\n",
            "  [-0.03213499  0.00381348 -0.0323016  -0.02118363  0.03843411\n",
            "   -0.01977954 -0.0376313   0.00078212]\n",
            "  [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454\n",
            "    0.0447777   0.03903276  0.04508351]\n",
            "  [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467\n",
            "   -0.01063299 -0.04568898 -0.02832687]\n",
            "  [-0.00846242 -0.02669038 -0.03737707 -0.03100523  0.01753208\n",
            "   -0.00716165 -0.03958933  0.02342893]\n",
            "  [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467\n",
            "   -0.01063299 -0.04568898 -0.02832687]\n",
            "  [ 0.04840124 -0.03601875  0.00335134  0.01281032  0.03751023\n",
            "   -0.01557592  0.02940439  0.04567841]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]\n",
            "  [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077\n",
            "    0.0463694   0.04576981  0.02851266]]\n",
            "\n",
            " [[ 0.03787452 -0.02205776  0.02461043 -0.04462063  0.03276087\n",
            "   -0.03106458 -0.00696957 -0.00905617]\n",
            "  [-0.03256357 -0.04965434  0.03093023 -0.00784104  0.0271985\n",
            "   -0.00038449 -0.03985684 -0.02427249]\n",
            "  [ 0.00406151 -0.04067155 -0.0216952  -0.03526106  0.0099689\n",
            "   -0.01227249 -0.01924158 -0.03416069]\n",
            "  [ 0.00117755  0.03518093 -0.01943209  0.03198161 -0.02390835\n",
            "   -0.01308385 -0.03958635  0.04204347]\n",
            "  [ 0.03289417 -0.02797817 -0.00894807  0.00598838  0.00729679\n",
            "   -0.01798836 -0.02862849  0.00577153]\n",
            "  [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454\n",
            "    0.0447777   0.03903276  0.04508351]\n",
            "  [ 0.02656425 -0.03522559 -0.03719143 -0.00033368 -0.03100518\n",
            "    0.01129659  0.02967956 -0.0300315 ]\n",
            "  [ 0.00117755  0.03518093 -0.01943209  0.03198161 -0.02390835\n",
            "   -0.01308385 -0.03958635  0.04204347]\n",
            "  [ 0.0327018   0.04490184 -0.04767594  0.01570619 -0.01002353\n",
            "    0.03499526 -0.04567767 -0.00960311]\n",
            "  [ 0.04840124 -0.03601875  0.00335134  0.01281032  0.03751023\n",
            "   -0.01557592  0.02940439  0.04567841]\n",
            "  [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454\n",
            "    0.0447777   0.03903276  0.04508351]\n",
            "  [ 0.03289417 -0.02797817 -0.00894807  0.00598838  0.00729679\n",
            "   -0.01798836 -0.02862849  0.00577153]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,doc in enumerate(embeddings):\n",
        "    for j,word in enumerate(doc):\n",
        "        print(\"The encoding for \",j+1,\"th word\",\"in\",i+1,\"th document is : \\n\\n\",word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbVo7sVwmIj_",
        "outputId": "af1a3601-dac8-4eb6-e05b-a70aed8fdd7e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The encoding for  1 th word in 1 th document is : \n",
            "\n",
            " [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467 -0.01063299\n",
            " -0.04568898 -0.02832687]\n",
            "The encoding for  2 th word in 1 th document is : \n",
            "\n",
            " [ 0.00406151 -0.04067155 -0.0216952  -0.03526106  0.0099689  -0.01227249\n",
            " -0.01924158 -0.03416069]\n",
            "The encoding for  3 th word in 1 th document is : \n",
            "\n",
            " [-0.00846242 -0.02669038 -0.03737707 -0.03100523  0.01753208 -0.00716165\n",
            " -0.03958933  0.02342893]\n",
            "The encoding for  4 th word in 1 th document is : \n",
            "\n",
            " [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467 -0.01063299\n",
            " -0.04568898 -0.02832687]\n",
            "The encoding for  5 th word in 1 th document is : \n",
            "\n",
            " [-0.03213499  0.00381348 -0.0323016  -0.02118363  0.03843411 -0.01977954\n",
            " -0.0376313   0.00078212]\n",
            "The encoding for  6 th word in 1 th document is : \n",
            "\n",
            " [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454  0.0447777\n",
            "  0.03903276  0.04508351]\n",
            "The encoding for  7 th word in 1 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  8 th word in 1 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  9 th word in 1 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  10 th word in 1 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  11 th word in 1 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  12 th word in 1 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  1 th word in 2 th document is : \n",
            "\n",
            " [ 0.02495926 -0.02276956 -0.0166773  -0.0218321   0.01099371 -0.04513886\n",
            " -0.01044786  0.03824759]\n",
            "The encoding for  2 th word in 2 th document is : \n",
            "\n",
            " [ 0.0327018   0.04490184 -0.04767594  0.01570619 -0.01002353  0.03499526\n",
            " -0.04567767 -0.00960311]\n",
            "The encoding for  3 th word in 2 th document is : \n",
            "\n",
            " [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467 -0.01063299\n",
            " -0.04568898 -0.02832687]\n",
            "The encoding for  4 th word in 2 th document is : \n",
            "\n",
            " [-0.03213499  0.00381348 -0.0323016  -0.02118363  0.03843411 -0.01977954\n",
            " -0.0376313   0.00078212]\n",
            "The encoding for  5 th word in 2 th document is : \n",
            "\n",
            " [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454  0.0447777\n",
            "  0.03903276  0.04508351]\n",
            "The encoding for  6 th word in 2 th document is : \n",
            "\n",
            " [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467 -0.01063299\n",
            " -0.04568898 -0.02832687]\n",
            "The encoding for  7 th word in 2 th document is : \n",
            "\n",
            " [-0.00846242 -0.02669038 -0.03737707 -0.03100523  0.01753208 -0.00716165\n",
            " -0.03958933  0.02342893]\n",
            "The encoding for  8 th word in 2 th document is : \n",
            "\n",
            " [ 0.00021515  0.04049387 -0.04500476 -0.00864762 -0.02606467 -0.01063299\n",
            " -0.04568898 -0.02832687]\n",
            "The encoding for  9 th word in 2 th document is : \n",
            "\n",
            " [ 0.04840124 -0.03601875  0.00335134  0.01281032  0.03751023 -0.01557592\n",
            "  0.02940439  0.04567841]\n",
            "The encoding for  10 th word in 2 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  11 th word in 2 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  12 th word in 2 th document is : \n",
            "\n",
            " [ 0.00998991 -0.0211266   0.01373998  0.00513347  0.02413077  0.0463694\n",
            "  0.04576981  0.02851266]\n",
            "The encoding for  1 th word in 3 th document is : \n",
            "\n",
            " [ 0.03787452 -0.02205776  0.02461043 -0.04462063  0.03276087 -0.03106458\n",
            " -0.00696957 -0.00905617]\n",
            "The encoding for  2 th word in 3 th document is : \n",
            "\n",
            " [-0.03256357 -0.04965434  0.03093023 -0.00784104  0.0271985  -0.00038449\n",
            " -0.03985684 -0.02427249]\n",
            "The encoding for  3 th word in 3 th document is : \n",
            "\n",
            " [ 0.00406151 -0.04067155 -0.0216952  -0.03526106  0.0099689  -0.01227249\n",
            " -0.01924158 -0.03416069]\n",
            "The encoding for  4 th word in 3 th document is : \n",
            "\n",
            " [ 0.00117755  0.03518093 -0.01943209  0.03198161 -0.02390835 -0.01308385\n",
            " -0.03958635  0.04204347]\n",
            "The encoding for  5 th word in 3 th document is : \n",
            "\n",
            " [ 0.03289417 -0.02797817 -0.00894807  0.00598838  0.00729679 -0.01798836\n",
            " -0.02862849  0.00577153]\n",
            "The encoding for  6 th word in 3 th document is : \n",
            "\n",
            " [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454  0.0447777\n",
            "  0.03903276  0.04508351]\n",
            "The encoding for  7 th word in 3 th document is : \n",
            "\n",
            " [ 0.02656425 -0.03522559 -0.03719143 -0.00033368 -0.03100518  0.01129659\n",
            "  0.02967956 -0.0300315 ]\n",
            "The encoding for  8 th word in 3 th document is : \n",
            "\n",
            " [ 0.00117755  0.03518093 -0.01943209  0.03198161 -0.02390835 -0.01308385\n",
            " -0.03958635  0.04204347]\n",
            "The encoding for  9 th word in 3 th document is : \n",
            "\n",
            " [ 0.0327018   0.04490184 -0.04767594  0.01570619 -0.01002353  0.03499526\n",
            " -0.04567767 -0.00960311]\n",
            "The encoding for  10 th word in 3 th document is : \n",
            "\n",
            " [ 0.04840124 -0.03601875  0.00335134  0.01281032  0.03751023 -0.01557592\n",
            "  0.02940439  0.04567841]\n",
            "The encoding for  11 th word in 3 th document is : \n",
            "\n",
            " [-0.04762596 -0.03199545 -0.00610454  0.00913912  0.04712454  0.0447777\n",
            "  0.03903276  0.04508351]\n",
            "The encoding for  12 th word in 3 th document is : \n",
            "\n",
            " [ 0.03289417 -0.02797817 -0.00894807  0.00598838  0.00729679 -0.01798836\n",
            " -0.02862849  0.00577153]\n"
          ]
        }
      ]
    }
  ]
}