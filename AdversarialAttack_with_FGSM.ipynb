{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redpineK/deeplearning/blob/master/AdversarialAttack_with_FGSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6VMjXBNBDqb"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Created on Thu Oct 27 18:58:00 2022\n",
        "\n",
        "Adversarial Attack with FGSM\n",
        "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm?hl=ko\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 8)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,\n",
        "                                                     weights='imagenet')\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "# ImageNet 클래스 레이블\n",
        "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions"
      ],
      "metadata": {
        "id": "87tweSKMBxgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지가 MobileNetV2에 전달될 수 있도록 전처리해주는 헬퍼 메서드(helper function)\n",
        "def preprocess(image):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = image/255\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "  image = image[None, ...]\n",
        "  return image\n",
        "\n",
        "# 확률 벡터에서 레이블을 추출해주는 헬퍼 메서드\n",
        "def get_imagenet_label(probs):\n",
        "  return decode_predictions(probs, top=1)[0][0]"
      ],
      "metadata": {
        "id": "FTiJzL5PB0Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', \n",
        "   'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\n",
        "image_raw = tf.io.read_file(image_path)\n",
        "image = tf.image.decode_image(image_raw)\n",
        "\n",
        "image = preprocess(image)\n",
        "image_probs = pretrained_model.predict(image)\n",
        "print(\"image_probs == \", image_probs)\n",
        "print(\"len(image_probs) == \", len(image_probs[0]))\n",
        "idx_max = np.argmax(image_probs)\n",
        "print(\"idx_max == \", idx_max, \" : \", image_probs[0][idx_max])"
      ],
      "metadata": {
        "id": "KWr_ZMiiB3nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(image[0])\n",
        "_, image_class, class_confidence = get_imagenet_label(image_probs)\n",
        "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L8sqo8CcB6qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "def create_adversarial_pattern(input_image, input_label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(input_image)\n",
        "    prediction = pretrained_model(input_image)\n",
        "    # print(\"KSW np.argmax(prediction) == \", np.argmax(prediction) )\n",
        "    loss = loss_object(input_label, prediction)\n",
        "    # print(\"KSW loss == \", loss)\n",
        "\n",
        "  # 입력 이미지에 대한 손실 함수의 기울기를 구합니다.\n",
        "  gradient = tape.gradient(loss, input_image)\n",
        "  # print(\"gradient.shape == \", gradient.shape)\n",
        "  # 왜곡을 생성하기 위해 그래디언트의 부호를 구합니다.\n",
        "  signed_grad = tf.sign(gradient)\n",
        "  # print(\"sign_grad.shape == \", signed_grad.shape)\n",
        "  return signed_grad"
      ],
      "metadata": {
        "id": "s88__BW0B9q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지의 레이블을 원-핫 인코딩 처리합니다.\n",
        "labrador_retriever_index = 208\n",
        "label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
        "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
        "\n",
        "perturbations = create_adversarial_pattern(image, label)\n",
        "plt.imshow(perturbations[0])"
      ],
      "metadata": {
        "id": "666r9_beCBVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(image, description):\n",
        "  _, label, confidence = get_imagenet_label(pretrained_model.predict(image))\n",
        "  plt.figure()\n",
        "  plt.imshow(image[0])\n",
        "  plt.title('{} \\n {} : {:.2f}% Confidence'.format(description,\n",
        "                                                   label, confidence*100))\n",
        "  plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "jgxk2NzjCK5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [0, 0.01, 0.1, 0.15, 0.2]\n",
        "descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input')\n",
        "                for eps in epsilons]\n",
        "\n",
        "for i, eps in enumerate(epsilons):\n",
        "  adv_x = image + eps*perturbations\n",
        "  adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
        "  display_images(adv_x, descriptions[i])"
      ],
      "metadata": {
        "id": "DdQIwPazCRmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U9rc-RpjCWyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}