{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMafNIW6G5gPQD2LPqmmXv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redpineK/deeplearning/blob/master/wordembedding_prractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "출처 - https://wikidocs.net/32105\n",
        "출처 - https://taeguu.tistory.com/69"
      ],
      "metadata": {
        "id": "77jjMqatNYUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1FYnKQLNTbU",
        "outputId": "71883f20-07df-4f79-928b-9d47e431b929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 :  [[1, 3, 4], [1, 2, 5], [6, 2, 7, 8]]\n",
            "단어 집합 :  {'나는': 1, '학교에': 2, '밥을': 3, '먹었다': 4, '갔다': 5, '오늘': 6, '선생님이': 7, '오셨다': 8}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# train_text = \"The earth is an awesome place live\"\n",
        "text = [\"나는 밥을 먹었다\", \"나는 학교에 갔다\", \"오늘 학교에 선생님이 오셨다\"]\n",
        "# 단어 집합 생성\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text)\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "# 정수 인코딩\n",
        "word_index = tokenizer.word_index\n",
        "print(\"정수 인코딩 : \",sequences)\n",
        "print(\"단어 집합 : \",word_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pad_sequences(sequences, maxlen=4, padding='post')\n",
        "print(data)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MCEjb6uNp6A",
        "outputId": "22b1c8e6-462c-426d-9a9b-94846f4b0df9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 3 4 0]\n",
            " [1 2 5 0]\n",
            " [6 2 7 8]]\n",
            "(3, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, embedding_dim, input_length=4))\n",
        "model.compile('rmsprop','mse')\n",
        "model.summary\n",
        "print(\"input array: \", data.shape)\n",
        "output_array = model.predict(data)\n",
        "print(\"output array: \", output_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N6cNM5gSatA",
        "outputId": "b7c69463-1bdb-4901-b0bc-d0f3cd6c3175"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0008e84560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input array:  (3, 4)\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "output array:  (3, 4, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"첫번째 문장 embedding 결과 : \", output_array[0][0])\n",
        "print(\"두번째 문장 embedding 결과 : \", output_array[1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJiIXU80XD7Y",
        "outputId": "8d812716-6e8d-44c6-dcc2-41ce00ee4a18"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 문장 embedding 결과 :  [ 0.02549931  0.00573844 -0.0313284   0.02795484  0.03318924  0.02546461\n",
            " -0.04146696 -0.00453953  0.04116144  0.01345712  0.01004329  0.04576221\n",
            " -0.02661508  0.02259971  0.00019739  0.04076651  0.03691976 -0.01220553\n",
            "  0.01727128  0.04675208  0.04767982  0.03141779 -0.02067733  0.01823011\n",
            " -0.02536675  0.01861408 -0.01715596 -0.03122287  0.04869511 -0.01129771\n",
            "  0.0200212  -0.04884242  0.03302152 -0.04145394 -0.02602971  0.04042307\n",
            "  0.0047039  -0.00766909 -0.00318252 -0.01364858  0.00625874 -0.04773426\n",
            "  0.00827658  0.01779832  0.03293863 -0.02912314  0.03277463  0.01181341\n",
            " -0.01059031 -0.01498593  0.01595111 -0.02037647 -0.03093036  0.04011032\n",
            " -0.01833414 -0.03132057  0.0341225   0.02172519  0.0282363  -0.00629539\n",
            "  0.00572466  0.01425943  0.03551254  0.00095893 -0.00253319 -0.01421244\n",
            "  0.01046241  0.0171574   0.01787332 -0.00429909 -0.0032467   0.01614984\n",
            "  0.00884765 -0.03575505 -0.03874158 -0.00590372 -0.03032322  0.02590361\n",
            " -0.04629814 -0.03590786 -0.00037811 -0.00591316  0.04825756  0.00982178\n",
            " -0.02289506  0.03757176 -0.03875832 -0.03747842 -0.01462436  0.02873906\n",
            "  0.01502366  0.01913914  0.00334675  0.02991373 -0.01082573 -0.03460224\n",
            "  0.00764715  0.04020036  0.02570898 -0.0104175 ]\n",
            "두번째 문장 embedding 결과 :  [ 0.02549931  0.00573844 -0.0313284   0.02795484  0.03318924  0.02546461\n",
            " -0.04146696 -0.00453953  0.04116144  0.01345712  0.01004329  0.04576221\n",
            " -0.02661508  0.02259971  0.00019739  0.04076651  0.03691976 -0.01220553\n",
            "  0.01727128  0.04675208  0.04767982  0.03141779 -0.02067733  0.01823011\n",
            " -0.02536675  0.01861408 -0.01715596 -0.03122287  0.04869511 -0.01129771\n",
            "  0.0200212  -0.04884242  0.03302152 -0.04145394 -0.02602971  0.04042307\n",
            "  0.0047039  -0.00766909 -0.00318252 -0.01364858  0.00625874 -0.04773426\n",
            "  0.00827658  0.01779832  0.03293863 -0.02912314  0.03277463  0.01181341\n",
            " -0.01059031 -0.01498593  0.01595111 -0.02037647 -0.03093036  0.04011032\n",
            " -0.01833414 -0.03132057  0.0341225   0.02172519  0.0282363  -0.00629539\n",
            "  0.00572466  0.01425943  0.03551254  0.00095893 -0.00253319 -0.01421244\n",
            "  0.01046241  0.0171574   0.01787332 -0.00429909 -0.0032467   0.01614984\n",
            "  0.00884765 -0.03575505 -0.03874158 -0.00590372 -0.03032322  0.02590361\n",
            " -0.04629814 -0.03590786 -0.00037811 -0.00591316  0.04825756  0.00982178\n",
            " -0.02289506  0.03757176 -0.03875832 -0.03747842 -0.01462436  0.02873906\n",
            "  0.01502366  0.01913914  0.00334675  0.02991373 -0.01082573 -0.03460224\n",
            "  0.00764715  0.04020036  0.02570898 -0.0104175 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "0VX6N-ZcOBuR"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 토큰화\n",
        "tokenized_text = [['Hope', 'to', 'see', 'you', 'soon'], ['Nice', 'to', 'see', 'you', 'again']]\n",
        "\n",
        "# 2. 각 단어에 대한 정수 인코딩\n",
        "encoded_text = [[0, 1, 2, 3, 4],[5, 1, 2, 3, 6]]\n",
        "\n",
        "# 3. 위 정수 인코딩 데이터가 아래의 임베딩 층의 입력이 된다.\n",
        "vocab_size = 7\n",
        "embedding_dim = 2\n",
        "Embedding(vocab_size, embedding_dim, input_length=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0p8CH8BN3IR",
        "outputId": "d5a1a909-ef8a-41b1-8f79-21310b4ef6bc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7f0008e253d0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 32\n",
        "hidden_units = 32\n",
        "# input_length = 4\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length = 4))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVyyjM8EOGYo",
        "outputId": "21083cf4-4f75-446a-8d67-58f16b03fd27"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_20 (Embedding)    (None, 4, 32)             320000    \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 322,113\n",
            "Trainable params: 322,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K-DmxJk2OGOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}