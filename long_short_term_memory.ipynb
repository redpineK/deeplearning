{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tavld8Ci5wj_"
      },
      "source": [
        "# Long Short-Term Memory (LSTM)\n",
        "\n",
        "Date: 2019-09-14  \n",
        "Author: skettee  \n",
        "Categories: Deep Learning, Recurrent Neural Network  \n",
        "Tags: PoS, Tokenization, LSTM, many-to-one      \n",
        "<!--eofm-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgIvQNr05wkA"
      },
      "source": [
        "감성 분석(Sentiment Analysis)을 위해서 텍스트 데이터를 변환하는 방법과 LSTM에 대해 알아보고 keras를 이용해서 모델링을 해보자!\n",
        "<!--more-->\n",
        "\n",
        "실제로 돌려 보고 싶으면 구글 코랩으로 ~  \n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/skettee/notebooks/blob/master/long_short_term_memory.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlabSMUf5wkB"
      },
      "source": [
        "## 문제 (Problem)\n",
        "\n",
        "👤 상사\n",
        "\n",
        "> 오~ 간단한 감성 분석기를 만들었군  \n",
        "> 근데 이건 애들 장난이고...  \n",
        "> 네이버가 제공하는 영화 리뷰 데이터로   \n",
        "> 제대로 된 감성 분석기를 만들어 보게    \n",
        "> 데이터는 아래에 있네   \n",
        ">\n",
        "> https://github.com/e9t/nsmc\n",
        "\n",
        "⚙️ 엔지니어\n",
        "\n",
        "> 프로젝트가 쌓여만 간다...   \n",
        "> 이제   \n",
        "> 떠날 때가 된것인가...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkdPXE735wkB"
      },
      "source": [
        "## 데이터 수집 (Data Collection)\n",
        "\n",
        "https://github.com/e9t/nsmc 에서 데이터 정보를 알아보자   \n",
        "\n",
        "**Data description**\n",
        "- Each file is consisted of three columns: id, document, label\n",
        "    - id: The review id, provieded by Naver\n",
        "    - document: The actual review\n",
        "    - label: The sentiment class of the review. (0: negative, 1: positive)\n",
        "    - Columns are delimited with tabs (i.e., .tsv format; but the file extension is .txt for easy access for novices)\n",
        "- 200K reviews in total\n",
        "    - ratings.txt: All 200K reviews\n",
        "    - ratings_test.txt: 50K reviews held out for testing\n",
        "    - ratings_train.txt: 150K reviews for training\n",
        "    \n",
        "**Characteristics**\n",
        "- All reviews are shorter than 140 characters\n",
        "- Each sentiment class is sampled equally (i.e., random guess yields 50% accuracy)\n",
        "    - 100K negative reviews (originally reviews of ratings 1-4)\n",
        "    -100K positive reviews (originally reviews of ratings 9-10)\n",
        "    - Neutral reviews (originally reviews of ratings 5-8) are excluded\n",
        "\n",
        "⚙️ 엔지니어\n",
        "\n",
        "> ratings_test.txt, ratings_train.txt를 다운로드 하자  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2DjKjKW75wkC",
        "outputId": "9047df9c-aebc-4b16-d2ff-8abfa2e0ab5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.github.com/e9t/nsmc/master/ratings_train.txt\n",
            "14630912/14628807 [==============================] - 0s 0us/step\n",
            "14639104/14628807 [==============================] - 0s 0us/step\n",
            "Downloading data from https://raw.github.com/e9t/nsmc/master/ratings_test.txt\n",
            "4898816/4893335 [==============================] - 0s 0us/step\n",
            "4907008/4893335 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "train_fname = 'ratings_train.tsv'\n",
        "test_fname = 'ratings_test.tsv'\n",
        "train_origin = 'https://raw.github.com/e9t/nsmc/master/ratings_train.txt'\n",
        "test_origin = 'https://raw.github.com/e9t/nsmc/master/ratings_test.txt'\n",
        "\n",
        "train_path = get_file(train_fname, train_origin)\n",
        "test_path = get_file(test_fname, test_origin)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_path)"
      ],
      "metadata": {
        "id": "rvYHfLrP6M5G",
        "outputId": "33380e38-a456-4c94-8d4b-4862b1770079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/ratings_train.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root/.keras/datasets/"
      ],
      "metadata": {
        "id": "Bqd3Z41z6XB0",
        "outputId": "34778dbc-cd9a-4418-c861-021e330ca281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "B6mkkgtb6bt9",
        "outputId": "db588b95-564b-49de-f249-f33304861dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ratings_test.tsv  ratings_train.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yMC4RJN5wkD"
      },
      "source": [
        "### Rating 데이터 프레임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dEBk7qg45wkD",
        "outputId": "34beb695-6b83-4ac4-dd5f-e734202a8de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34d4acce-5416-4846-8ba5-6df7149c745e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d4acce-5416-4846-8ba5-6df7149c745e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34d4acce-5416-4846-8ba5-6df7149c745e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34d4acce-5416-4846-8ba5-6df7149c745e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv(train_path, sep='\\t') # tsv file\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M9qmwQFI5wkE",
        "outputId": "fa5d8dcd-5c63-4843-b6af-e13809c4feaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           document  label\n",
              "0  6270596                                                굳 ㅋ      1\n",
              "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
              "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
              "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5699b1d-e431-4081-a10f-9a33e6052c69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5699b1d-e431-4081-a10f-9a33e6052c69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5699b1d-e431-4081-a10f-9a33e6052c69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5699b1d-e431-4081-a10f-9a33e6052c69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "test_df = pd.read_csv(test_path, sep='\\t') # tsv file\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4SO1Vf5wkF"
      },
      "source": [
        "## 데이터 분석 (Data Analysis)\n",
        "\n",
        "빵꾸난거 부터 확인하고 제거하자    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u2DfjLSU5wkF",
        "outputId": "ca72f5ed-14dc-4dd6-9efd-9f738f92ff4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          False\n",
              "document     True\n",
              "label       False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_df.isnull().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-B4i_GXS5wkF"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.dropna(axis=0).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().any()"
      ],
      "metadata": {
        "id": "iXWY_T4I7Mxs",
        "outputId": "579dc285-0383-42be-e52a-d3c9d16f469e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          False\n",
              "document    False\n",
              "label       False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Wyapllld5wkF",
        "outputId": "11693819-aa5c-4a68-e18c-fb2946f0f48d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          False\n",
              "document     True\n",
              "label       False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_df.isnull().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "acJQcdq_5wkG"
      },
      "outputs": [],
      "source": [
        "test_df = test_df.dropna(axis=0).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.isnull().any()"
      ],
      "metadata": {
        "id": "xJZ37kMR7Txl",
        "outputId": "90af5998-04c1-43f8-9e7a-e8628d6708ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          False\n",
              "document    False\n",
              "label       False\n",
              "dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gqmatq25wkG"
      },
      "source": [
        "데이터의 크기와 레이블에 따른 분포를 확인하자  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-R83yQGa5wkG",
        "outputId": "8bd4a666-71d7-4bd6-8d39-72da47818dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (149995, 3)\n",
            "Label 0 in Train data: 75170 (50.1%)\n",
            "Label 1 in Train data: 74825 (49.9%)\n",
            "\n",
            "Test data shape:  (49997, 3)\n",
            "Label 0 in Test data: 24826 (49.7%)\n",
            "Label 1 in Test data: 25171 (50.3%)\n"
          ]
        }
      ],
      "source": [
        "print('Train data shape: ', train_df.shape)\n",
        "n_lebel = len(train_df[train_df.label == 0])\n",
        "print('Label 0 in Train data: {} ({:.1f}%)'.format(n_lebel, n_lebel*100/len(train_df)))\n",
        "n_lebel = len(train_df[train_df.label == 1])\n",
        "print('Label 1 in Train data: {} ({:.1f}%)'.format(n_lebel, n_lebel*100/len(train_df)))\n",
        "\n",
        "print('\\nTest data shape: ', test_df.shape)\n",
        "n_lebel = len(test_df[test_df.label == 0])\n",
        "print('Label 0 in Test data: {} ({:.1f}%)'.format(n_lebel, n_lebel*100/len(test_df)))\n",
        "n_lebel = len(test_df[test_df.label == 1])\n",
        "print('Label 1 in Test data: {} ({:.1f}%)'.format(n_lebel, n_lebel*100/len(test_df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THhCWySt5wkG"
      },
      "source": [
        "`id`컬럼은 필요 없으니 제거하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ID3cYaaX5wkH"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[['document', 'label']]\n",
        "test_df = test_df[['document', 'label']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WMph5G35wkH"
      },
      "source": [
        "## 데이터 전처리 (Data Preprocessing)\n",
        "   \n",
        "한글 텍스트를 RNN에 입력하기 위해서는 텍스트를 RNN이 처리하기 편한 형태로 분리해야 한다. 이렇게 텍스트를 분리하는 작업을 **토근화(Tokenization)** 라고 한다.  \n",
        "한글을 토큰화 하기 위해서 형태소 분석기를 사용한다. 다양한 한글 형태소 분석기가 존재하는데, 여기에서는 PyKomoran을 사용한다. 다른 형태소 분석기에 관심이 있으면 아래를 참조한다.  \n",
        "\n",
        "- [Mecap](https://bitbucket.org/eunjeon/mecab-ko-dic/src/master/)\n",
        "- [Khaiii](https://github.com/kakao/khaiii)\n",
        "- [Komoran](https://github.com/shin285/KOMORAN)\n",
        "\n",
        "\n",
        "⚙️ 엔지니어\n",
        "\n",
        "> 앞에서 본 이모티콘 감성분석에서      \n",
        "> 이모티콘을 텍스트로 변환했는데   \n",
        "> 반대로    \n",
        "> 텍스트를 이모티콘으로 변환하는 것을       \n",
        "> 토큰화(Tokenization)라고 생각하면  \n",
        "> 이해가 쉬울 것 같다...  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NycMGRPg5wkH"
      },
      "source": [
        "### 형태소 분석기 설치\n",
        "\n",
        "PyKomoran을 사용하기 위해서는 Java가 설치 되어 있어야 한다. 아래 명령어를 실행해서 Java가 설치되어 있는지 확인하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D9jRIGKb5wkH",
        "outputId": "20bf8f92-7e4e-4671-aea8-106f7b7bf56b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.16\" 2022-07-19\n",
            "OpenJDK Runtime Environment (build 11.0.16+8-post-Ubuntu-0ubuntu118.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.16+8-post-Ubuntu-0ubuntu118.04, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!java -version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YEOHaSO5wkH"
      },
      "source": [
        "PyKomoran을 설치한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BeqLWT_I5wkI",
        "outputId": "2b12b47c-0554-4946-f72e-4f8de3564055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyKomoran\n",
            "  Downloading PyKomoran-0.1.6.post1-py3-none-any.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 10.9 MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 66.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j, PyKomoran\n",
            "Successfully installed PyKomoran-0.1.6.post1 py4j-0.10.9.2\n"
          ]
        }
      ],
      "source": [
        "%pip install PyKomoran"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd1xnP335wkI"
      },
      "source": [
        "설치 확인을 위해 아래 코드를 실행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "967sZdTm5wkI",
        "outputId": "7394feb9-bd77-4605-a37a-c7cba4e54e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'①/SW 대한민국/NNP 은/JX 민주/NNG 공화국/NNG 이/VCP 다/EF ./SF'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from PyKomoran import *\n",
        "\n",
        "corpus = \"① 대한민국은 민주공화국이다.\"\n",
        "komoran = Komoran(\"STABLE\")\n",
        "komoran.get_plain_text(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx4zGunP5wkI"
      },
      "source": [
        "### 토큰화 (Tokenization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3bdKWaW5wkI"
      },
      "source": [
        "형태소 분석기는 문장을 품사(PoS)별로 분리해 준다. 모든 품사를 사용하지 않고 감성 분석에 필요하다고 판단이 되는 품사를 선정해서 토큰화를 진행한다.  \n",
        "\n",
        "#### 품사 (Part Of Speech)\n",
        "\n",
        "Komoran에서 정의하는 품사 종류는 아래 사이트를 참조.  \n",
        "품사표 (PoS Table): https://pydocs.komoran.kr/firststep/postypes.html\n",
        "\n",
        "#### 불용어 (Stop Words)\n",
        "\n",
        "RNN에 입력으로 들어가지 못하는 단어들을 말한다. 여기서는 들어가지 못하는 품사를 아래와 같이 정의한다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OmOYYIxw5wkI"
      },
      "outputs": [],
      "source": [
        "stop_pos_tags =  ['IC', 'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', \n",
        "                   'EF', 'ETN', 'ETM', 'XSA', 'SF', 'SP', 'SS', 'SE', 'SO', 'SL', 'SH', \n",
        "                   'SW', 'NF', 'NV', 'SN', 'NA']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTKkjqZg5wkI"
      },
      "source": [
        "#### 어간 원형 복원 (Lemmatization)\n",
        "\n",
        "동사와 형용사의 경우에는 어간(Stem)에 '다'를 붙여서 기본형으로 복원한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6ArUc18p5wkI"
      },
      "outputs": [],
      "source": [
        "def tokenize(corpus, stop_pos_tags):\n",
        "    result = []\n",
        "    pairs = komoran.get_list(corpus)\n",
        "    for pair in pairs:\n",
        "        morph = pair.get_first()\n",
        "        pos = pair.get_second()\n",
        "        if pos not in stop_pos_tags:\n",
        "            if pos in ['VV', 'VA', 'VX', 'VCP', 'VCN']:\n",
        "                morph = morph + '다'\n",
        "            result.append(morph)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7jJk-ns5wkJ"
      },
      "source": [
        "토큰을 만들고 리스트에 저장한다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u6ben1yc5wkJ",
        "outputId": "5a34b99a-47b3-407c-d6e2-5791715ff94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c6edfb2fa4b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtokens_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_pos_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-c27d40547cd5>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(corpus, stop_pos_tags)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_pos_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkomoran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmorph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PyKomoran/core.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_komoran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misInitialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKomoranError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Komoran is NOT initialized!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PyKomoran/core.py\u001b[0m in \u001b[0;36mget_list\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_komoran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0mpair_dict_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_komoran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mpair_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpair_dict_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1310\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o0.analyze.\n: java.lang.NullPointerException\n\tat kr.co.shineware.nlp.komoran.core.model.Lattice.putIrregularExtendTokens(Lattice.java:160)\n\tat kr.co.shineware.nlp.komoran.core.model.Lattice.put(Lattice.java:144)\n\tat kr.co.shineware.nlp.komoran.core.Komoran.insertLattice(Komoran.java:563)\n\tat kr.co.shineware.nlp.komoran.core.Komoran.irregularParsing(Komoran.java:556)\n\tat kr.co.shineware.nlp.komoran.core.Komoran.analyze(Komoran.java:243)\n\tat kr.co.shineware.nlp.komoran.core.Komoran.analyze(Komoran.java:189)\n\tat kr.co.shineware.nlp.pykomoran.KomoranEntryPoint.analyze(KomoranEntryPoint.java:142)\n\tat jdk.internal.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ],
      "source": [
        "tokens_list = []\n",
        "\n",
        "for i in range(len(train_df['document'])):\n",
        "    tokens_list.append(tokenize(train_df['document'][i], stop_pos_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iMsafY65wkJ"
      },
      "source": [
        "데이터 프레임에 넣어서 토큰이 제대로 만들어 졌는지 확인한다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cktnDn3E5wkJ"
      },
      "outputs": [],
      "source": [
        "train_df['tokens'] = tokens_list\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDcd6OUx5wkJ"
      },
      "source": [
        "토큰이 비어있는 열은 과감하게 제거한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK6Z190v5wkJ"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[train_df['tokens'].str.len() > 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTNEYVWt5wkJ"
      },
      "source": [
        "테스트 데이터도 동일하게 토큰을 추출하고 데이터프레임에 저장한다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq2CM7As5wkK"
      },
      "outputs": [],
      "source": [
        "tokens_list = []\n",
        "\n",
        "for i in range(len(test_df['document'])):\n",
        "    tokens_list.append(tokenize(test_df['document'][i], stop_pos_tags))\n",
        "test_df['tokens'] = tokens_list\n",
        "\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhLwh1VD5wkK"
      },
      "source": [
        "토큰이 비어있는 열은 과감하게 제거한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKw33AYI5wkK"
      },
      "outputs": [],
      "source": [
        "test_df = test_df[test_df['tokens'].str.len() > 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ikXydQc5wkK"
      },
      "source": [
        "## LSTM 모델링 (LSTM Modeling)\n",
        "\n",
        "RNN의 단점은 timestep이 증가하면 이전의 입력 데이터 정보가 사라진다는 것이다. 긴 문장의 경우에 timestep이 수백개가 되는 경우가 있다. 즉 RNN 레이어가 수백개가 되면 손실함수의 최소값을 찾기 위해 미분의 미분의 ... 미분을 수백번을 하게 되고 어느 지점 부터 미분값이 0이 되면 그 이전의 입력 데이터 정보는 사용할 수 없게 된다.      \n",
        "\n",
        "⚙️ 엔지니어\n",
        "\n",
        "> RNN이 알고보니  \n",
        "> '메멘토' 였다!   \n",
        ">\n",
        "> 그러나 엔지니어를 또 갈아서 해결했다.  \n",
        "> 그것은 바로...  \n",
        "\n",
        "### LSTM (Long Short-Term Memory)\n",
        "\n",
        "RNN unit에 이전 데이터의 정보를 저장하고 있는 메모리 셀(memory cell) 함수($c^{\\lt t \\gt}$)와 메모리 셀을 유지할 것인지 업데이트 할 것인지를 결정하는 게이트(gate) 함수($\\Gamma_u, \\Gamma_f, \\Gamma_o$)를 추가한 것이 LSTM이다.  \n",
        "\n",
        "![LSTM Unit](https://skettee.github.io/post/long_short_term_memory/lstm.png)\n",
        "\n",
        "$\\begin{align} \n",
        "\\tilde c^{\\lt t \\gt} & = tanh\\left(W_{ca}a^{\\lt t-1 \\gt} + W_{cx}x^{\\lt t \\gt} + b_c\\right) \\\\  \n",
        "\\Gamma_u & = \\sigma \\left( W_{ua}a^{\\lt t-1 \\gt} + W_{ux}x^{\\lt t \\gt} + b_u \\right) \\\\\n",
        "\\Gamma_f & = \\sigma \\left( W_{fa}a^{\\lt t-1 \\gt} + W_{fx}x^{\\lt t \\gt} + b_f \\right) \\\\\n",
        "\\Gamma_o & = \\sigma \\left( W_{oa}a^{\\lt t-1 \\gt} + W_{ox}x^{\\lt t \\gt} + b_o \\right) \\\\\n",
        "c^{\\lt t \\gt} & = \\Gamma_u * \\tilde c^{\\lt t \\gt} + \\Gamma_f * c^{\\lt t-1 \\gt} \\\\\n",
        "a^{\\lt t \\gt} & = \\Gamma_o * tanh (c^{\\lt t \\gt}) \\\\\n",
        "\\hat y^{\\lt t \\gt} & = W_{ya}a^{\\lt t \\gt} + b_y \n",
        "\\end{align}$  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFBkGJaV5wkK"
      },
      "source": [
        "⚙️ 엔지니어  \n",
        "\n",
        "> 게이트($\\Gamma$)의 열고($\\Gamma = 1$) 닫고($\\Gamma = 0$)를  \n",
        "> 학습에 의해서 결정 ($(W_u, b_u), (W_f, b_f), (W_o, b_o)$) 한다.  \n",
        "> 게이트($\\Gamma$)의 상태에 따라서  \n",
        "> 메모리 셀 ($c^{\\lt t \\gt}$)을 업데이트 할건지 ($\\tilde c^{\\lt t \\gt}$)    \n",
        "> 이전것을 유지할건지 ($c^{\\lt t-1 \\gt}$)\n",
        "> 결정한다.  \n",
        ">\n",
        "> 트랜지스터 같네... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6kL_XJZ5wkK"
      },
      "source": [
        "### Many-to-One Model\n",
        "\n",
        "감성분석(Sentiment Anaysis)에 사용되는 many to one 모델을 사용한다.  \n",
        "훈련 리뷰 개수 136,927개를 사용하고, time step은 40으로 고정한다.  \n",
        "리뷰마다 토큰의 수가 다르므로 40이 안되면 0으로 채우고(padding) 40이 넘으면 그 이상은 잘라 버린다(clipping)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6xakZ2E5wkL"
      },
      "source": [
        "### 정리\n",
        "1. Input Layer\n",
        "    1. Batch size는 136927개   \n",
        "    2. Time step은 40개 ($T_x = 40$)   \n",
        "    3. Feature 개수는 입력에 들어가는 토큰 1개  \n",
        "2. LSTM Layer\n",
        "    1. 128개 유닛으로 구성한다.  \n",
        "    2. Dropout을 0.2로 설정한다.    \n",
        "3. Output Layer\n",
        "    1. 활성 함수는 시그모이드(Sigmoid)를 사용한다.\n",
        "4. Loss funtion 은 binary_crossentropy 를 사용한다.  \n",
        "5. Optimizer 는 Adam을 사용한다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAH2Cfnk5wkL"
      },
      "source": [
        "## 케라스(Keras)로 모델링(Modeling)\n",
        "\n",
        "### 데이터 변환 (Data Transformation)\n",
        "\n",
        "토큰을 숫자로 변환(Encoding)하고, 입력 토큰의 개수를 동일한 크기로 맞춘다. 출력은 0과 1로 변환한다.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgxbmxJi5wkL"
      },
      "source": [
        "#### Encoding\n",
        "\n",
        "토큰을 숫자로 변환하고 tokenizer를 파일에 저장한다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTx0dpXr5wkL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "tokenizer_name = 'keras_naver_review_tokenizer.pickle'\n",
        "save_path = os.path.join(os.getcwd(), tokenizer_name)\n",
        "\n",
        "max_words = 35000\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token = True)\n",
        "tokenizer.fit_on_texts(train_df.tokens)\n",
        "train_df.tokens = tokenizer.texts_to_sequences(train_df.tokens)\n",
        "test_df.tokens = tokenizer.texts_to_sequences(test_df.tokens)\n",
        "\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXZI7oTu5wkL"
      },
      "outputs": [],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9TS0RZW5wkL",
        "outputId": "09957fa4-2876-4d21-988d-0e27e6ffd9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape:  (136927,)\n",
            "Y_train shape:  (136927,)\n",
            "\n",
            "X_test shape:  (45780,)\n",
            "Y_test shape:  (45780,)\n"
          ]
        }
      ],
      "source": [
        "X_train = train_df.tokens\n",
        "Y_train = train_df.label\n",
        "\n",
        "X_test = test_df.tokens\n",
        "Y_test = test_df.label\n",
        "\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('Y_train shape: ', Y_train.shape)\n",
        "print('\\nX_test shape: ', X_test.shape)\n",
        "print('Y_test shape: ', Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEnC-yfA5wkL"
      },
      "source": [
        "#### Padding\n",
        "\n",
        "Time step은 40으로 고정한다. 리뷰마다 토큰의 수가 다르므로 40이 안되면 0으로 채우고(padding) 40이 넘으면 그 이상은 잘라 버린다(clipping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXbdOVAZ5wkL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len=40\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aOUoZ9-5wkL"
      },
      "source": [
        "#### 이진 분류 (Binary classification)\n",
        "\n",
        "출력 데이터를 0과 1로 변환한다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AzmVKBE5wkM",
        "outputId": "dd891aec-28d0-457c-c986-7a22e6da0b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(136927, 1)\n",
            "(45780, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "# Train\n",
        "batch_size = Y_train.shape[0]\n",
        "input_dim = 1\n",
        "Y_train = encoder.fit_transform(Y_train) # Labeling\n",
        "Y_train = np.reshape(Y_train, (batch_size, input_dim)) # Reshape\n",
        "# Test\n",
        "batch_size = Y_test.shape[0]\n",
        "Y_test = encoder.transform(Y_test) # Labeling\n",
        "Y_test = np.reshape(Y_test, (batch_size, input_dim)) # Reshape\n",
        "\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKSSp9Pj5wkM"
      },
      "source": [
        "### 모델링 (Modeling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8vdyT1F5wkM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5_7lbp75wkM"
      },
      "source": [
        "### 모델 훈련 (Train Model)\n",
        "\n",
        "커피 한잔 하세여~ ☕️"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTHS70Ni5wkM",
        "outputId": "324e0938-58c7-4a5c-e74d-58c7002810ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "136927/136927 [==============================] - 429s 3ms/sample - loss: 0.3903 - acc: 0.8231\n",
            "Epoch 2/5\n",
            "136927/136927 [==============================] - 429s 3ms/sample - loss: 0.3104 - acc: 0.8662\n",
            "Epoch 3/5\n",
            "136927/136927 [==============================] - 430s 3ms/sample - loss: 0.2687 - acc: 0.8867\n",
            "Epoch 4/5\n",
            "136927/136927 [==============================] - 430s 3ms/sample - loss: 0.2322 - acc: 0.9037\n",
            "Epoch 5/5\n",
            "136927/136927 [==============================] - 430s 3ms/sample - loss: 0.1984 - acc: 0.9197\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(X_train, Y_train, batch_size=32, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvE5Jos5wkM"
      },
      "source": [
        "### 모델 테스트 (Test Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Nny0xmM5wkM",
        "outputId": "a4e6ff88-4377-4ffb-f2f8-ab6f749bf5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45780/45780 [==============================] - 24s 519us/sample - loss: 0.4006 - acc: 0.8480\n",
            "Test loss: 0.4006009472697622\n",
            "Test accuracy: 0.8479904\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test, Y_test, batch_size=32)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBMHjN2V5wkM"
      },
      "source": [
        "### 모델 저장 (Save Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5hqm28u5wkM",
        "outputId": "4bd2f46f-0cd7-41ab-87a0-62397d16899c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved trained model at /home/dataman/myWork/deeplearning/keras_naver_review_trained_model.h5 \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "save_dir = os.getcwd()\n",
        "model_name = 'keras_naver_review_trained_model.h5'\n",
        "\n",
        "# Save model and weights\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7n68MN95wkN"
      },
      "source": [
        "## 해결 (Solution)\n",
        "\n",
        "⚙️ 엔지니어\n",
        "  \n",
        "> review_text에 리뷰를 적어서 실행하면   \n",
        "> 감성 분석 예측 결과가 나옵니다.   \n",
        "> 정확도는 84% 입니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiN-J2wB5wkN"
      },
      "outputs": [],
      "source": [
        "from  tensorflow.keras.models import load_model\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def load_tokenizer(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return tokenizer\n",
        "\n",
        "load_dir = os.getcwd()\n",
        "model_name = 'keras_naver_review_trained_model.h5'\n",
        "tokenizer_name = 'keras_naver_review_tokenizer.pickle'\n",
        "model_path = os.path.join(load_dir, model_name)\n",
        "tokenizer_path = os.path.join(load_dir, tokenizer_name)\n",
        "\n",
        "model = load_model(model_path)\n",
        "tokenizer = load_tokenizer(tokenizer_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzlTomBD5wkN",
        "outputId": "0bdfd900-f42f-4188-fd1a-64104966abf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "재미있는영화입니다. : GOOD\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PyKomoran import *\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len=40\n",
        "komoran = Komoran(\"STABLE\")\n",
        "stop_pos_tags =  ['IC', 'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', \n",
        "                   'EF', 'ETN', 'ETM', 'XSA', 'SF', 'SP', 'SS', 'SE', 'SO', 'SL', 'SH', \n",
        "                   'SW', 'NF', 'NV', 'SN', 'NA']\n",
        "\n",
        "def tokenize(corpus, stop_pos_tags):\n",
        "    result = []\n",
        "    pairs = komoran.get_list(corpus)\n",
        "    for pair in pairs:\n",
        "        morph = pair.get_first()\n",
        "        pos = pair.get_second()\n",
        "        if pos not in stop_pos_tags:\n",
        "            if pos in ['VV', 'VA', 'VX', 'VCP', 'VCN']:\n",
        "                morph = morph + '다'\n",
        "            result.append(morph)\n",
        "    return result\n",
        "\n",
        "def predict_sentiment(text, model):\n",
        "    tokens = []\n",
        "    tokens.append(tokenize(text, stop_pos_tags))\n",
        "    tokens = tokenizer.texts_to_sequences(tokens)\n",
        "    x_test = pad_sequences(tokens, maxlen=max_len)\n",
        "    predict = model.predict(x_test)\n",
        "    if predict[0] > 0.5:\n",
        "        return 'GOOD'\n",
        "    else:\n",
        "        return 'BAD'\n",
        "\n",
        "review_text = '재미있는영화입니다.'\n",
        "result = predict_sentiment(review_text, model)\n",
        "\n",
        "print('{} : {}'.format(review_text, result))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}