{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redpineK/deeplearning/blob/master/SimpleVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LwDuhzvAwRx"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "print(\"Tensorflow Versoin == \", tf.__version__)\n",
        "print(\"Keras Version == \", keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (28, 28, 1)\n",
        "batch_size = 16\n",
        "latent_dim = 2  # 잠재 공간의 차원: 2D 평면\n",
        "\n",
        "input_img = keras.Input(shape=img_shape)\n",
        "x = layers.Conv2D(32, 3,\n",
        "                  padding='same', activation='relu')(input_img)\n",
        "x = layers.Conv2D(64, 3,\n",
        "                  padding='same', activation='relu',\n",
        "                  strides=(2, 2))(x)\n",
        "x = layers.Conv2D(64, 3,\n",
        "                  padding='same', activation='relu')(x)\n",
        "x = layers.Conv2D(64, 3,\n",
        "                  padding='same', activation='relu')(x)\n",
        "shape_before_flattening = K.int_shape(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# 잠재 벡터 생성\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)"
      ],
      "metadata": {
        "id": "r6uaaAy4B9uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 다음은 `z_mean`과 `z_log_var`를 사용하는 코드입니다. \n",
        "# 이 두 파라미터가 `input_img`를 생성한 통계 분포의 파라미터라고 가정하고 잠재 공간 포인트 `z`를 생성합니다. \n",
        "# 여기에서 (케라스의 백엔드 기능으로 만든) 일련의 코드를 `Lambda` 층으로 감쌉니다. \n",
        "# 케라스에서는 모든 것이 층이므로 기본 층을 사용하지 않은 코드는 `Lambda`로 (또는 직접 만든 층으로) 감싸야 합니다.\n",
        "\n",
        "\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
        "                              mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n"
      ],
      "metadata": {
        "id": "RriTD_XoCLbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음 코드는 디코더 구현입니다. \n",
        "# 벡터 `z`를 이전 특성 맵 차원으로 크기를 바꾸고 몇 개의 합성곱 층을 사용해 최종 출력 이미지를 만듭니다. \n",
        "# 최종 이미지는 원본 `input_img`와 차원이 같습니다.\n",
        "\n",
        "\n",
        "\n",
        "# Input에 z를 주입합니다\n",
        "decoder_input = layers.Input(K.int_shape(z)[1:])\n",
        "\n",
        "# 입력을 업샘플링합니다\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]),\n",
        "                 activation='relu')(decoder_input)\n",
        "\n",
        "# 인코더 모델의 마지막 Flatten 층 직전의 특성 맵과 같은 크기를 가진 특성 맵으로 z의 크기를 바꿉니다\n",
        "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
        "\n",
        "# Conv2DTranspose 층과 Conv2D 층을 사용해 z를 원본 입력 이미지와 같은 크기의 특성 맵으로 디코딩합니다\n",
        "x = layers.Conv2DTranspose(32, 3,\n",
        "                           padding='same', activation='relu',\n",
        "                           strides=(2, 2))(x)\n",
        "x = layers.Conv2D(1, 3,\n",
        "                  padding='same', activation='sigmoid')(x)\n",
        "# 특성 맵의 크기가 원본 입력과 같아집니다\n",
        "\n",
        "# 디코더 모델 객체를 만듭니다\n",
        "decoder = Model(decoder_input, x)\n",
        "\n",
        "# 모델에 z를 주입하면 디코딩된 z를 출력합니다\n",
        "z_decoded = decoder(z)"
      ],
      "metadata": {
        "id": "AJdqlrefCohA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# 일반적인 샘플 기준의 함수인 `loss(y_true, y_pred)` 형태는 VAE의 이중 손실에 맞지 않습니다. \n",
        "# `add_loss` 내장 메서드를 사용하는 층을 직접 만들어 임의의 손실을 정의하겠습니다.\n",
        "\n",
        "\n",
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "\n",
        "    def vae_loss(self, x, z_decoded):\n",
        "        x = K.flatten(x)\n",
        "        z_decoded = K.flatten(z_decoded)\n",
        "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "        kl_loss = -5e-4 * K.mean(\n",
        "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        z_decoded = inputs[1]\n",
        "        loss = self.vae_loss(x, z_decoded)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        # 출력 값을 사용하지 않습니다\n",
        "        return x\n",
        "\n",
        "# 입력과 디코딩된 출력으로 이 층을 호출하여 모델의 최종 출력을 얻습니다\n",
        "y = CustomVariationalLayer()([input_img, z_decoded])\n"
      ],
      "metadata": {
        "id": "5aZARUKGCtBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 이제 모델 객체를 만들고 훈련할 준비가 되었습니다. \n",
        "# 층에서 손실을 직접 다루기 때문에 `compile` 메서드에서 손실을 지정하지 않습니다(`loss=None`). \n",
        "# 그 결과 훈련하는 동안 타깃 데이터를 전달하지 않아도 됩니다(다음 코드처럼 모델의 `fit` 메서드에 `x_train`만 전달합니다).\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "vae = Model(input_img, y)\n",
        "vae.compile(optimizer='rmsprop', loss=None)\n",
        "vae.summary()\n",
        "\n",
        "# MNIST 숫자 이미지에서 VAE를 훈련합니다\n",
        "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "vae.fit(x=x_train, y=None,\n",
        "        shuffle=True,\n",
        "        epochs=10,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, None))\n"
      ],
      "metadata": {
        "id": "dODDlaqxCyFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# MNIST 데이터셋으로 모델의 훈련을 마치면 디코더 네트워크를 사용하여 잠재 공간의 임의의 벡터를 이미지로 변환할 수 있습니다:\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Display a 2D manifold of the digits\n",
        "n = 15  # 15 × 15 숫자의 그리드를 출력합니다\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# 싸이파이 ppf 함수를 사용하여 일정하게 떨어진 간격마다 잠재 변수 z의 값을 만듭니다\n",
        "# 잠재 공간의 사전 확률은 가우시안입니다\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
        "        x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 샘플링된 숫자의 그리드는 다른 숫자 클래스 사이에서 완벽하게 연속된 분포를 보여줍니다. \n",
        "# 잠재 공간의 한 경로를 따라서 한 숫자가 다른 숫자로 자연스럽게 바뀝니다. \n",
        "# 이 공간의 특정 방향은 어떤 의미를 가집니다. 예를 들어 '6으로 가는 방향', '9로 가는 방향' 등입니다.\n"
      ],
      "metadata": {
        "id": "e-4agS_UC4jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TkcjHyDbanOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}